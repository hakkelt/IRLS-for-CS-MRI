

using FFTW, LinearAlgebra, EllipsisNotation, FunctionOperators, Base.Cartesian, ProgressMeter, Random,
    Distributed

@generated function blocks_to_array!(
        output::AbstractArray{T, D},
        input::AbstractArray{T, D2},
        block_shape::NTuple{D, Int},
        shifts::NTuple{D, Int}) where {T, D, D2}
    @assert 2*D == D2 "Dimension mismatch! Proper dimensionality: 2*ndims(output) = ndims(input)"
    quote
        @nloops($D, block_idx, input, begin
                @nloops($D, point_idx, d -> axes(input, $D + d),
                    d -> begin
                        pos_in_output_d = (block_idx_d - 1) * shifts[d] + point_idx_d
                        pos_in_output_d > size(output, d) && break
                    end,
                    @inbounds @nref($D, output, pos_in_output) +=
                        input[@ntuple($D, block_idx)..., @ntuple($D, point_idx)...])
            end)
        return output
    end
end

@generated function array_to_blocks!(
        output::AbstractArray{T, D2},
        input::AbstractArray{T, D},
        block_shape::NTuple{D, Int},
        shifts::NTuple{D, Int}) where {T, D, D2}
    @assert 2*D == D2 "Dimension mismatch! Proper dimensionality: ndims(output) = 2*ndims(input)"
    quote
        @nloops($D, block_idx, output, begin
                @nloops($D, point_idx, d -> axes(output, $D + d),
                    d -> pos_in_output_d = (block_idx_d - 1) * shifts[d] + point_idx_d,
                    @inbounds output[@ntuple($D, block_idx)..., @ntuple($D, point_idx)...] = 
                        @nany($D, d -> pos_in_output_d > size(input, d)) ?
                            zero($T) :
                            @nref($D, input, pos_in_output))
            end)
        return output
    end
end

function hanning(shape)
    shape = shape isa Number ? (shape,) : shape
    hanningFunction(x, width) = 0.5 - 0.5 * cos(2œÄ * x / max(1, (width - (width % 2))))
    multiDimHanning(coord) = prod([hanningFunction(coord[i]-1, shape[i]) for i in 1:length(shape)])
    [multiDimHanning(coord) for coord in CartesianIndices(tuple(UnitRange.(1, shape)...))]
end

# Some fancy stuff for naming
#   e.g. the array-to-block operator for the scale with block-size 8 as "ùìë‚Çà"
digitToSubscript(d) = string(Char(Int('‚ÇÄ')+d))
numberToSubscript(n) = join([digitToSubscript(Int(d)-48) for d in string(n)])

function _get_‚Ñ≥(block_width, img_shape, dtype)
    
    block_shape = min.(img_shape, block_width)
    shifts = (block_shape .+ 1) .√∑ 2
    num_blocks = ceil.(Int, img_shape ./ shifts .- 1)
    ndim = length(num_blocks)
    
    # Blocking operator:
    #  - forward embeds blocks in the output image in a sliding window manner
    #  - backward rearranges the image to blocks
    blockedShape = (num_blocks..., block_shape...)
    ùìë = FunctionOperator{dtype}(name = "ùìë"*numberToSubscript(block_width),
        forw = (b, x) -> begin
            b .= zero(dtype)
            blocks_to_array!(b, reshape(x, blockedShape), block_shape, shifts)
        end,
        backw = (b, x) -> array_to_blocks!(b, x, block_shape, shifts),
        inDims = blockedShape,
        outDims = img_shape)
    
    # Multiplication with Hanning window to cancel the effect of sliding window.
    # Blocks are multiplied with the squre root of the window before and after the blocking operator.
    HanningWindow = reshape(sqrt.(hanning(block_shape)), fill(1, ndim)..., block_shape...)
    ùì¶ = FunctionOperator{dtype}(name = "ùì¶"*numberToSubscript(block_width),
        forw = (b, x) -> reshape(b, size(x)) .= x .* HanningWindow,
        backw = (b, x) -> reshape(b, size(x)) .= x .* HanningWindow,
        inDims = (num_blocks..., block_shape...),
        outDims = (num_blocks..., block_shape...))
    
    return ùìë * ùì¶
end
    
function _get_ùí©(t, samp, smap, frame_coils, img_shape, nc, dType)
    nx, ny = img_shape
    scaling = convert(dType, ‚àö(nx*ny))
    mask_with_scaling = reshape(samp[t], nx, ny, 1) .* scaling
    reshaped_smap = convert.(dType, smap)
    smap_conj_with_scaling = conj.(reshaped_smap) ./ scaling
    FFT_plan = plan_fft(frame_coils[Threads.threadid()], (1,2))
    iFFT_plan = inv(FFT_plan)
    E = FunctionOperator{dType}(name = "E", 
        forw = (b, x) -> begin # Don't ask me, why did Mr Otazo use ifft instead of fft...
                xcoils‚ÇÅ = frame_coils[Threads.threadid()]
                xcoils‚ÇÇ = b
                xcoils‚ÇÅ .= reshape(x, (nx, ny, 1)) .* reshaped_smap
                ifftshift!(xcoils‚ÇÇ, xcoils‚ÇÅ, (1, 2))
                mul!(xcoils‚ÇÅ, iFFT_plan, xcoils‚ÇÇ)
                fftshift!(b, xcoils‚ÇÅ, (1, 2))
                b .*= mask_with_scaling
            end,
        backw = (b, y) -> begin # But he used it consistently, so it doesn't make a big difference
                xcoils‚ÇÅ = frame_coils[Threads.threadid()]
                xcoils‚ÇÇ = similar(xcoils‚ÇÅ)
                ifftshift!(xcoils‚ÇÇ, y, (1, 2))
                mul!(xcoils‚ÇÅ, FFT_plan, xcoils‚ÇÇ)
                fftshift!(xcoils‚ÇÇ, xcoils‚ÇÅ, (1, 2))
                xcoils‚ÇÇ .*= smap_conj_with_scaling
                sum!(reshape(b, (nx, ny, 1)), xcoils‚ÇÇ)
                b
            end,
        inDims = (nx, ny), outDims = (nx, ny, nc))
end

function _get_ùíü¬≤(t, dcf‚Çú, C, num_ro, tr_per_frame, dtype)
    FunctionOperator{dtype}(name = "ùíü¬≤"*numberToSubscript(t),
        forw = (output‚Çú, input‚Çú) -> error("Not implemented"),
        backw = (output‚Çú, input‚Çú) -> begin
                output‚Çú .= input‚Çú .* dcf‚Çú[t]
            end,
        inDims = (C, num_ro, tr_per_frame),
        outDims = (C, num_ro, tr_per_frame))
end

function _get_ùíü(t, dcf‚Çú, C, num_ro, tr_per_frame, dtype)
    FunctionOperator{dtype}(name = "ùíü"*numberToSubscript(t),
        forw = (output‚Çú, input‚Çú) -> begin
                output‚Çú .= input‚Çú .* sqrt.(dcf‚Çú[t])
            end,
        backw = (output‚Çú, input‚Çú) -> begin
                output‚Çú .= input‚Çú .* sqrt.(dcf‚Çú[t])
            end,
        inDims = (C, num_ro, tr_per_frame),
        outDims = (C, num_ro, tr_per_frame))
end

function _get_Œª(block_width, Œª, img_shape, T, dtype)
    
    block_shape = min.(img_shape, block_width)
    shifts = (block_shape .+ 1) .√∑ 2
    num_blocks = ceil.(Int, img_shape ./ shifts .- 1)
    
    N = prod(block_shape)
    B = prod(num_blocks)
    
    return Œª * (‚àöN + ‚àöT + ‚àö(2log(B)))
end

function MaxEig!(op, x, iter_num)
    Œª‚Çò‚Çê‚Çì = Inf
    #@showprogress 0.2 "Normalization of dcf... "
    for i in 1:iter_num
        mul!(x, op, x)
        Œª‚Çò‚Çê‚Çì = norm(x, 2)
        x ./= Œª‚Çò‚Çê‚Çì
    end
    Œª‚Çò‚Çê‚Çì
end

function _normalize(coord, dcf, ksp, mps, img_shape, C, T, tr_per_frame, max_power_iter, dtype)
    
    # Estimate maximum eigenvalue.
    print("Normalization of dcf:\t\t\t")
    @time begin
        coord‚Çú‚ÇÅ = @view coord[:, :, 1:tr_per_frame]
        dcf‚Çú‚ÇÅ = reshape(@view(dcf[:, 1:tr_per_frame]), 1, :, tr_per_frame)
        plan = SigJl.nufft_plan(coord‚Çú‚ÇÅ, img_shape, threaded = true)
        adj_plan = plan'
        ùí©‚Çú‚ÇÅ = FunctionOperator{dtype}(name = "ùí©‚Çú‚ÇÅ",
            forw = (b, x) -> mul!(b, plan, x),
            backw = (b, x) -> mul!(b, adj_plan, x),
            inDims = img_shape,
            outDims = size(coord‚Çú‚ÇÅ))
        ùíü¬≤‚Çú‚ÇÅ = FunctionOperator{dtype}(name = "ùíü‚Çú‚ÇÅ",
            forw = (b, x) -> b .= x .* dcf‚Çú‚ÇÅ,
            inDims = size(coord‚Çú‚ÇÅ),
            outDims = size(coord‚Çú‚ÇÅ))
        x‚ÇÄ = convert.(eltype(ksp), rand(img_shape...))
        Œª‚Çò‚Çê‚Çì = MaxEig!(ùí©‚Çú‚ÇÅ' * ùíü¬≤‚Çú‚ÇÅ * ùí©‚Çú‚ÇÅ, x‚ÇÄ, max_power_iter)
        dcf ./= abs(Œª‚Çò‚Çê‚Çì)
    end
    
    # Estimate scaling
    print("Normalization of ksp:\t\t\t")
    @time begin
        dcf = reshape(dcf, 1, size(dcf)...)
        img = SigJl.nufft_adjoint(coord, ksp .* dcf, oshape=(C, img_shape...), threaded=true)
                #progressTitle="Normalization of ksp... ", progress_dt=0.2)
        img .*= conj.(mps)
        ksp ./= norm(sum(img, dims=1), 2)
    end
    
    dcf, ksp
end

function normalize_L!(L)
    D = ndims(L) √∑ 2
    L_norm = mapslices(norm, L, dims=D+1:2D)
    L ./= L_norm
    L_norm
end

function normalize_R!(R‚Çú)
    R = parent(R‚Çú[1])
    R ./= mapslices(norm, R, dims=ndims(R))
end

function _init_L(blocked_shape, dtype)
    L = randn(dtype, blocked_shape)
    normalize_L!(L)
    L
end

function _init_R(blocked_shape, D, T, dtype)
    Array{dtype}(undef, (blocked_shape[1:D]..., fill(1, D)..., T))
end

function powerIter_R!(R‚±º‚Çú, A·¥¥y, A·¥¥yL·¥¥‚±º, t, ùíú, ‚Ñ≥‚±º, ksp‚Çú, L‚±º)
    mul!(A·¥¥y, ùíú', ksp‚Çú[t])
    for j in 1:length(R‚±º‚Çú)
        mul!(A·¥¥yL·¥¥‚±º[j], ‚Ñ≥‚±º[j]', A·¥¥y)
        A·¥¥yL·¥¥‚±º[j] .*= conj.(L‚±º[j])
        sum!(R‚±º‚Çú[j][t], A·¥¥yL·¥¥‚±º[j])
    end
end

function powerIter_L!(L‚±º, A·¥¥y, t, ùíú, ‚Ñ≥‚±º, ksp‚Çú, R‚±º‚Çú)
    mul!(A·¥¥y, ùíú', ksp‚Çú[t])
    for j in 1:length(L‚±º)
        L‚±º[j] .+= (‚Ñ≥‚±º[j]' * A·¥¥y) .* conj.(R‚±º‚Çú[j][t])
    end
end

function reconstructImage(L‚±º, R‚±º‚Çú, ‚Ñ≥‚±º, nx, ny, T, J, dtype)
    img = zeros(dtype, nx, ny, T)
    temp = Array{dtype}(undef, nx, ny)
    for t in 1:T
        for j in 1:J
            img[.., t] .+= mul!(temp, ‚Ñ≥‚±º[j], L‚±º[j] .* R‚±º‚Çú[j][t])
        end
    end
    img
end

function _power_method!(L‚±º, R‚±º‚Çú, ùí©‚Çú, ‚Ñ≥‚±º, ksp‚Çú, img_shape, D, max_power_iter, dtype)
    
    œÉ‚±º = nothing
    J = length(L‚±º)
    T = length(R‚±º‚Çú[1])
    
    # We need these only to avoid re-allocation of same buffers over and over again
    L‚±º_buffers = [deepcopy(L‚±º) for _ in 1:Threads.nthreads()]
    A·¥¥y_buffers = [similar(ksp‚Çú[1], img_shape) for _ in 1:Threads.nthreads()]
    
    for it in 1:max_power_iter
        # R‚±º‚Çú = calc_norm_of_blocks(‚Ñ≥‚±º·¥¥(A‚Çú·¥¥‚ãÖy‚Çú·¥¥)‚ãÖL‚±º·¥¥)
        #p = Progress(T+1, 0.2, "Power iteration (R, $it/$max_power_iter)... ")
        #@time begin
            Threads.@threads for t in 1:T
                A·¥¥y_buffer = A·¥¥y_buffers[Threads.threadid()]
                A·¥¥yL‚±º·¥¥_buffer = L‚±º_buffers[Threads.threadid()]
                powerIter_R!(R‚±º‚Çú, A·¥¥y_buffer, A·¥¥yL‚±º·¥¥_buffer, t, ùí©‚Çú(t), ‚Ñ≥‚±º, ksp‚Çú, L‚±º)
                #next!(p)
            end
            pmap(normalize_R!, R‚±º‚Çú)
            #finish!(p)
        #end
        
        # L‚±º = Œ£‚Çú(‚Ñ≥‚±º·¥¥(A‚Çú·¥¥‚ãÖy‚Çú·¥¥)‚ãÖR‚±º‚Çú·¥¥)
        #p = Progress(T+3, 0.2, "Power iteration (L, $it/$max_power_iter)... ")
        #@time begin
            Threads.@threads for i in 1:Threads.nthreads()
                fill!.(L‚±º_buffers[i], zero(dtype))
            end
            #next!(p)
            Threads.@threads for t in 1:T
                A·¥¥y_buffer = A·¥¥y_buffers[Threads.threadid()]
                L‚±º_buffer = L‚±º_buffers[Threads.threadid()]
                powerIter_L!(L‚±º_buffer, A·¥¥y_buffer, t, ùí©‚Çú(t), ‚Ñ≥‚±º, ksp‚Çú, R‚±º‚Çú)
                #next!(p)
            end
            for i in 1:Threads.nthreads(), j in 1:J
                i == 1 ? L‚±º[j] .= L‚±º_buffers[i][j] : L‚±º[j] .+= L‚±º_buffers[i][j]
            end
            #next!(p)
            
            œÉ‚±º = pmap(normalize_L!, L‚±º) # save the norm of L at each level
            #finish!(p)
        #end
        
    end

    for j in 1:J
        L‚±º[j] .*= sqrt.(œÉ‚±º[j])
        parent(R‚±º‚Çú[j][1]) .*= sqrt.(œÉ‚±º[j])
    end
    
    œÉ‚±º
end

function _sgd(X·¥≥·µÄ, ùí©‚Çú, ‚Ñ≥‚±º, ksp‚Çú, L‚±º, R‚±º‚Çú, T, Œ±, Œ≤, œÉ‚±º, Œª‚±º, D, max_epoch, decay_epoch, img_shape, dtype)
    J = length(R‚±º‚Çú)
    
    cost_vec = OffsetVector{real(dtype)}(undef, 0:max_epoch)
    time_vec = OffsetVector{Float64}(undef, 0:max_epoch)
    time_vec[0] = 0
    img = reconstructImage(L‚±º, R‚±º‚Çú, ‚Ñ≥‚±º, nx, ny, T, J, dtype)
    cost_vec[0] = norm(X·¥≥·µÄ - img)
    
    N = Threads.nthreads()
    img‚Çô = [similar(R‚±º‚Çú[1], dtype, img_shape) for n in 1:N]
    ‚àáL‚Çô‚±º = [[similar(L‚±º[j]) for j in 1:J] for n in 1:N]
    ‚àáR‚Çô‚±º = [[similar(R‚±º‚Çú[j][1]) for j in 1:J] for n in 1:N]
    loss‚Çô = fill(zero(eltype(Œª‚±º[1])), N)
    
    interval = 1
    @showprogress interval "MSLR " for epoch in 1:max_epoch
        time_vec[epoch] = time_vec[epoch-1] + @elapsed begin
            loss = 0
            #p = Progress(T, 0.2, "Epoch {epoch}/{max_epoch}... ")
            for t‚Çô in Iterators.partition(randperm(T), N)
                Threads.@threads for n in 1:length(t‚Çô)
                    ‚àáL‚±º, ‚àáR‚±º, t, img = ‚àáL‚Çô‚±º[n], ‚àáR‚Çô‚±º[n], t‚Çô[n], img‚Çô[n]
                    loss‚Çô[n] = _step!(‚àáL‚±º, ‚àáR‚±º, t, ùí©‚Çú, ‚Ñ≥‚±º, img, ksp‚Çú, img_shape,
                                        L‚±º, R‚±º‚Çú, œÉ‚±º, Œª‚±º, D, dtype)
                    #next!(p)
                end
                loss += sum(loss‚Çô[1:length(t‚Çô)])
                ‚àáL‚±º = ‚àáL‚Çô‚±º[1]; [‚àáL‚±º .+= ‚àáL‚Çô‚±º[n] for n in 2:length(t‚Çô)]
                for j in 1:J
                    L‚±º[j] .-= Œ± .* Œ≤^(epoch √∑ decay_epoch) .* ‚àáL‚±º[j]
                    [R‚±º‚Çú[j][t‚Çô[n]] .-= Œ± .* ‚àáR‚Çô‚±º[n][j] for n in 1:length(t‚Çô)]
                end
            end
        end
        
        img = reconstructImage(L‚±º, R‚±º‚Çú, ‚Ñ≥‚±º, nx, ny, T, J, dtype)
        cost_vec[epoch] = norm(X·¥≥·µÄ - img)
        #iterationPrint("k" => epoch, "‚ÄñX·¥≥·µÄ - X·µè‚Äñ‚ÇÇ" => cost_vec[epoch])
        
    end
    
    cost_vec, time_vec
end

function _step!(‚àáL‚±º, ‚àáR‚±º, t, ùí©‚Çú, ‚Ñ≥‚±º, img, ksp‚Çú, img_shape, L‚±º, R‚±º‚Çú, œÉ‚±º, Œª‚±º, D, dtype)
    J = length(R‚±º‚Çú)
    T = length(R‚±º‚Çú[1])
    # Form image.
    fill!(img, zero(dtype))
    temp = similar(img)
    [img .+= mul!(temp, ‚Ñ≥‚±º[j], L‚±º[j] .* R‚±º‚Çú[j][t]) for j in 1:J]

    # Data consistency.
    ùí© = ùí©‚Çú(t)
    ksp_hat = ùí© * img
    diff_hat = ksp_hat .-= ksp‚Çú[t]
    loss = 0.5 * norm(diff_hat)^2
    diff = mul!(img, ùí©', diff_hat)

    # Compute gradient.
    for j in 1:J

        # Loss.
        loss += Œª‚±º[j] / 2 * (norm(L‚±º[j])^2 / T + norm(R‚±º‚Çú[j][t])^2)
        isnan(loss) && error("loss is NaN")
        (isinf(loss)) && throw(OverflowError("loss overflow"))

        # L gradient.
        diff_blocks = ‚Ñ≥‚±º[j]' * diff
        @. ‚àáL‚±º[j] = T * (diff_blocks * conj(R‚±º‚Çú[j][t]) + Œª‚±º[j] / T * L‚±º[j])

        # R gradient.
        sum!(‚àáR‚±º[j], diff_blocks .*= conj.(L‚±º[j]))
        ‚àáR‚±º[j] .+= Œª‚±º[j] .* R‚±º‚Çú[j][t]

        # Precondition.
        ‚àáL‚±º[j] ./= J .* œÉ‚±º[j] .+ Œª‚±º[j]
        ‚àáR‚±º[j] ./= J .* œÉ‚±º[j] .+ Œª‚±º[j]

    end

    return loss
end

function MultiScaleLowRank(
        X·¥≥·µÄ::AbstractArray,                     # ground truth for MSE evaluation
        ksp::AbstractArray,                     # under-sampled data
        coord::AbstractArray,                   # sampling mask
        mps::AbstractArray;                     # sensitivity maps
        img_size::NTuple = size(X·¥≥·µÄ),           # size of output matrix
        block_widths::NTuple = (32, 64, 128),# block sizes
        Œ±::Real = 1,                            # step size
        Œ≤::Real = 0.5,                          # decay for step size
        Œª::Real = 1e-8,                         # scaling factor for Lagrangian multiplier
        max_epoch::Int = 10,                    # number of iterations over all frames
        decay_epoch::Int = max_epoch √∑ 3,       # number of iterations over all frames
        max_power_iter::Int = 3,                # maximal number of power iterations at initialization
        verbose::Bool = false)                  # print rank and loss value in each iteration
    
    # Initialize variables
    @assert 3 ‚â§ length(img_size) ‚â§ 4
    if length(img_size) == 3
        nx,ny,nt = img_size
        nc = size(ksp)[end]
    else
        nx,ny,nt,nc = img_size
    end
    
    ## --- Initialization --- ##
    println(" ---- Initialization ----")
    dtype = eltype(ksp)
    img_shape = nx, ny
    D = length(img_shape)
    J = length(block_widths)
    T = nt
    
    Random.seed!(0)
    
    print("initialization:   ")
    @time begin
        # create views to access time frames more easily
        coord‚Çú = [@view coord[:,:,t] for t in 1:T]
        ksp‚Çú = [@view ksp[:,:,t,:] for t in 1:T]
        # Regularization parameters for each levels
        Œª‚±º = [_get_Œª(bw, Œª, img_shape, T, dtype) for bw in block_widths]
        # buffers for each thread to store intermediate results of shape (C, img_shape...)
        frame_coils = [similar(mps) for _ in 1:Threads.nthreads()]
        # Blocking operators (image array ‚ü∑ blocks)
        ‚Ñ≥‚±º = [_get_‚Ñ≥(bw, img_shape, dtype) for bw in block_widths]
        # NUFFT operators (lazily created to save memory)
        ùí©‚Çú = t -> _get_ùí©(t, coord‚Çú, mps, frame_coils, img_shape, nc, dtype)
        # Initialize L and R vectors
        L‚±º_init = [_init_L(‚Ñ≥‚±º[j].inDims, dtype) for j in 1:J]
        R‚±º_init = [_init_R(‚Ñ≥‚±º[j].inDims, D, T, dtype) for j in 1:J]
        R‚±º‚Çú_init = [[@view(R‚±º_init[j][.., t]) for t in 1:T] for j in 1:J]
    end
    
    print("power iterations: ")
    @time œÉ‚±º = _power_method!(L‚±º_init, R‚±º‚Çú_init, ùí©‚Çú, ‚Ñ≥‚±º, ksp‚Çú, img_shape, D, max_power_iter, dtype)
    
    println(" ---- Reconstruction ----")
    done = false
    cost_vec, time_vec = nothing, nothing
    while !done
        L‚±º, R‚±º‚Çú = deepcopy(L‚±º_init), deepcopy(R‚±º‚Çú_init)
        try
            cost_vec, time_vec = _sgd(X·¥≥·µÄ, ùí©‚Çú, ‚Ñ≥‚±º, ksp‚Çú, L‚±º, R‚±º‚Çú, T, Œ±, Œ≤, œÉ‚±º, Œª‚±º, D,
                max_epoch, decay_epoch, img_shape, dtype)
            done = true
        catch err
            if err isa OverflowError && err.msg == "loss overflow"
                Œ± *= Œ≤
                println("Reconstruction diverged. New step size: $Œ±")
                if Œ± < 1e-4
                    error("too small Œ± value, reconstruction seems not to converge...")
                end
            else
                rethrow(err)
            end
        end
    end
    
    img = zeros(dtype, nx, ny, nt)
    temp = Array{dtype}(undef, nx, ny)
    for t in 1:T
        for j in 1:J
            img[.., t] .+= mul!(temp, ‚Ñ≥‚±º[j], L‚±º_init[j] .* R‚±º‚Çú_init[j][t])
        end
    end
    
    return img, cost_vec, time_vec
end
